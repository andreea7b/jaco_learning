setup:
    prefix: 'j2s7s300_driver'
    model_filename: "jaco_dynamics"
    object_centers: {'HUMAN_CENTER': [-0.6,-0.55,0.0], 'LAPTOP_CENTER': [-0.7, 0.0, -0.05]}
    # for the features and weights that are shared between all goals
    common_feat_list: ['world_efficiency']
    #common_feat_list: ['efficiency_clip']
    common_feat_weights: [50.0]
    #common_feat_weights: [30.0]
    start: [180.0, 175.0, 180.0, 300.0, 180.0, 180.0, 190.0]
    #start: [180.0, 150.0, 180.0, 270.0, 180.0, 180.0, 190.0]
    goals: [
        #[140.0, 90.0, 180.0, 160.0, 270.0, 180.0, 280.0],
        #[220.0, 90.0, 180.0, 160.0, 270.0, 180.0, 280.0],
        [150.0, 130.0, 160.0, 240.0, 180.0, 172.0, 280.0],
        [210.0, 130.0, 200.0, 240.0, 180.0, 172.0, 280.0]
    ]
    visual_goals: [
        [150.0, 130.0, 160.0, 240.0, 180.0, 172.0, 280.0],
        [210.0, 130.0, 200.0, 240.0, 180.0, 172.0, 280.0],
        [123.0, 155.0, 131.0, 284.0, 180.0, 176.0, 189.0]
        #[180.0, 175.0, 180.0, 300.0, 180.0, 180.0, 190.0]
    ]
    # for generating goal-specific feature weights
    goal_dist_feat_weight: 0.0 #currently not implemented
    learned_goals: [
    #    "/root/catkin_ws/src/jaco_learning/data/pour_red_new_meirl_test2.pt",
    #    "/root/catkin_ws/src/jaco_learning/data/pour_red_pose_uc.pt",
    #    "/root/catkin_ws/src/jaco_learning/data/goto_green_pose_uc.pt"
    #    "/root/catkin_ws/src/jaco_learning/data/pour_red_meirl.pt",
    #    "/root/catkin_ws/src/jaco_learning/data/pour_red_meirl2.pt",
    #    "/root/catkin_ws/src/jaco_learning/data/goto_green_meirl.pt"
    ]
    T: 15.0
    timestep: 0.5
    demonstrations_save_path: "data/task2_demonstrations.npz"

planner:
    # These settings have been tuned for trajopt planner.
    type: "trajopt"
    max_iter: 50
    num_waypts: 5
    # prefer_angles should be False for preprogrammed goals to work
    prefer_angles: False #whether to use goal angles over goal poses
    use_constraint_learned: True

controller:
    # These settings have been tuned for PID controller.
    type: "pid"
    p_gain: 1.0
    i_gain: 0.0
    d_gain: 0.1
    epsilon: 0.10
    max_cmd: 40.0

learner:
    # # for baseline
    # betas: [1]
    # goal_beliefs: "none"
    # inference_method: "dragan"
    # assistance_method: "blend"
    # beta_method: "joint"
    # beta_priors: [1]
    # zero_input_assist: True
    # alpha_method: "prob"



    betas: [0.1, 1, 10.]
    goal_beliefs: "none" #if 'none' then uniform gets used
    #goal_beliefs: [0., 0., 0., 1.]
    #goal_beliefs: [0., 0., 1.]
    #goal_beliefs: [1., 0.]
    # inference method is "dragan", "collect", or "none"
    inference_method: "collect"
    #inference_method: "none"
    #assistance_method: "blend"
    assistance_method: "none"
    #beta_method: "joint"
    beta_method: "estimate"
    #beta_priors: [1] # if "joint" these are probabilities
    #beta_priors: [2, 2, 2] #if "estimate" these are exponential rate parameters
    #beta_priors: "none" #if 'none' then 0's are used
    #beta_priors: [0, 0, 0, -10000]
    beta_priors: [4., 4.]
    #beta_priors: [10., 10.]
    #beta_priors: [2, 2, -10000]
    zero_input_assist: False
    alpha_method: "beta"
    demonstration_save_path: ""
